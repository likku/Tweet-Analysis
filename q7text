                                                                                
scala> val tweet_time =  sqlContext.sql("select count(*),substr(from_unixtime(timestamp_ms),13,2) from table1 where timestamp_ms is not null group by substr(from_unixtime(timestamp_ms),13,2)")
tweet_time: org.apache.spark.sql.DataFrame = [_c0: bigint, _c1: string]

scala> tweet_time.show()
+----+---+                                                                      
| _c0|_c1|
+----+---+
|8416| 00|
|8710| 01|
|8951| 02|
|8718| 03|
|8783| 04|
|8775| 05|
|8831| 06|
|8670| 07|
|8867| 08|
|8905| 09|
|8895| 10|
|8705| 11|
|8728| 12|
|8864| 13|
|8841| 14|
|8875| 15|
|8681| 16|
|8695| 17|
|8659| 18|
|8540| 19|
+----+---+
only showing top 20 rows


scala> tweet_time.write.format("json").save("/home/ysahwanth/Desktop/q7output.json")
           
